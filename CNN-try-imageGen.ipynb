{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import keras.layers as layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from spp.SpatialPyramidPooling import SpatialPyramidPooling\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations\n",
    "FOLDER_LOCATION = \"E:\\Downloads\\Cats-vs-Dogs-all\"\n",
    "TEST_FOLDER = \"test\"\n",
    "TRAIN_FOLDER = \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aims\n",
    "## Keras\n",
    "I aim to generate a CNN that is capable of identifying the difference between cats and dogs\n",
    "\n",
    "\n",
    "Layer 1:\n",
    "CNN\n",
    "Number of channels: 200\n",
    "Kernel: [3, 3]\n",
    "activation: RELU\n",
    "[2, 2]\n",
    "\n",
    "Layer 2:\n",
    "CNN\n",
    "Number of channels: 200\n",
    "Kernel: [3, 3]\n",
    "activation: RELU\n",
    "[2, 2]\n",
    "\n",
    "Layer 4:\n",
    "CNN\n",
    "Number of channels: 100\n",
    "Kernel: [3, 3]\n",
    "activation: RELU\n",
    "[2, 2]\n",
    "\n",
    "Potential Global Pooling layer\n",
    "\n",
    "Layer 5:\n",
    "FC\n",
    "nodes: 300\n",
    "dropout 0.4\n",
    "activation: RELU\n",
    "\n",
    "Layer 6:\n",
    "FC\n",
    "nodes: 200\n",
    "dropout: 0.4\n",
    "activation: RELU\n",
    "\n",
    "Layer 7:\n",
    "FC\n",
    "nodes: 125\n",
    "dropout: 0.4\n",
    "activation: RELU\n",
    "\n",
    "Layer 8:\n",
    "FC\n",
    "nodes: 2\n",
    "activation: Linear\n",
    "\n",
    "Use Logits to obtain system accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "22500 training samples\n"
     ]
    }
   ],
   "source": [
    "# Load in the training data and shuffle it with KFolds and a validation dataset\n",
    "BATCH_SIZE = 100\n",
    "IMAGE_HEIGHT = 300\n",
    "IMAGE_WIDTH = 300\n",
    "image_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                          horizontal_flip=True,\n",
    "                                          rotation_range=50,\n",
    "                                          validation_split=0.1)\n",
    "train_generator = image_data_generator.flow_from_directory(os.path.join(FOLDER_LOCATION, TRAIN_FOLDER), classes=['cat', 'dog'], \n",
    "                                                           class_mode=\"categorical\", \n",
    "                                                           batch_size=BATCH_SIZE, \n",
    "                                                           target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), \n",
    "                                                           subset=\"training\")\n",
    "\n",
    "validation_generator = image_data_generator.flow_from_directory(os.path.join(FOLDER_LOCATION, TRAIN_FOLDER), \n",
    "                                                                classes=['cat', 'dog'],\n",
    "                                                                class_mode=\"categorical\", \n",
    "                                                                batch_size=BATCH_SIZE, \n",
    "                                                                target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), \n",
    "                                                                subset=\"validation\")\n",
    "print(\"{} training samples\".format(train_generator.samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 298, 298, 6)       168       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 294, 294, 10)      1510      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 292, 292, 6)       546       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 290, 290, 5)       275       \n",
      "_________________________________________________________________\n",
      "spatial_pyramid_pooling_1 (S (None, 130)               0         \n",
      "_________________________________________________________________\n",
      "FC_1 (Dense)                 (None, 100)               13100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "FC_2 (Dense)                 (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "FC_3 (Dense)                 (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "FC_output (Dense)            (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 30,851\n",
      "Trainable params: 30,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "LAYER_1_CNN = 200\n",
    "LAYER_2_CNN = 100\n",
    "LAYER_3_CNN = 50\n",
    "\n",
    "LAYER_1_FC = 100\n",
    "LAYER_2_FC = 100\n",
    "LAYER_3_FC = 50\n",
    "LAYER_OUTPUT = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Convolution2D(filters=6, kernel_size=(3,3), strides=(1,1), activation=\"relu\", \n",
    "                               input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "model.add(layers.Convolution2D(filters=10, kernel_size=(5,5), strides=(1,1), activation=\"relu\"))\n",
    "model.add(layers.Convolution2D(filters=6, kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "model.add(layers.Convolution2D(filters=5, kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "model.add(SpatialPyramidPooling([1, 5]))\n",
    "model.add(layers.Dense(LAYER_1_FC, activation=\"relu\", name=\"FC_1\"))\n",
    "model.add(layers.Dropout(0.50))\n",
    "model.add(layers.Dense(LAYER_2_FC, activation=\"relu\", name=\"FC_2\"))\n",
    "model.add(layers.Dropout(0.50))\n",
    "model.add(layers.Dense(LAYER_3_FC, activation=\"relu\", name=\"FC_3\"))\n",
    "model.add(layers.Dropout(0.50))\n",
    "model.add(layers.Dense(LAYER_OUTPUT, activation=\"softmax\", name=\"FC_output\"))\n",
    "model.summary()\n",
    "print(IMAGE_HEIGHT)\n",
    "print(IMAGE_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 664s 3s/step - loss: 0.6685 - acc: 0.5825 - val_loss: 0.6135 - val_acc: 0.6684\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 462s 2s/step - loss: 0.6001 - acc: 0.6788 - val_loss: 0.5283 - val_acc: 0.7316\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 462s 2s/step - loss: 0.5602 - acc: 0.7186 - val_loss: 0.5243 - val_acc: 0.7336\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 463s 2s/step - loss: 0.5407 - acc: 0.7338 - val_loss: 0.5081 - val_acc: 0.7476\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 464s 2s/step - loss: 0.5300 - acc: 0.7418 - val_loss: 0.5236 - val_acc: 0.7360\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 460s 2s/step - loss: 0.5209 - acc: 0.7445 - val_loss: 0.4796 - val_acc: 0.7712\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 465s 2s/step - loss: 0.5126 - acc: 0.7517 - val_loss: 0.4692 - val_acc: 0.7836\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 463s 2s/step - loss: 0.5049 - acc: 0.7555 - val_loss: 0.4696 - val_acc: 0.7760\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 461s 2s/step - loss: 0.4987 - acc: 0.7632 - val_loss: 0.4715 - val_acc: 0.7752\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 463s 2s/step - loss: 0.4896 - acc: 0.7668 - val_loss: 0.4564 - val_acc: 0.7848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ebc60e940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "# Trains for 10 epochs.\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=train_generator.samples//BATCH_SIZE, \n",
    "                    epochs=10, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=validation_generator.samples//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_sixties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model_sixties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
